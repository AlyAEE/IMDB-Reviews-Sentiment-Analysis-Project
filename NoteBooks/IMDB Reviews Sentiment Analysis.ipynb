{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1058d933-f4d8-4755-8a3d-b8d1548bbc8f",
   "metadata": {},
   "source": [
    "\n",
    "- Ask yourself why would they have selected this problem for the challenge? What are some gotchas in this domain I should know about?\n",
    "- What types of visualizations will help me grasp the nature of the problem / data?\n",
    "- What feature engineering might help improve the signal?\n",
    "- Which modeling techniques are good at capturing the types of relationships I see in this data?\n",
    "- Now that I have a model, how can I be sure that I didn't introduce a bug in the code? If results are too good to be true, they probably are!\n",
    "- What are some of the weaknesses of the model and and how can the model be improved with additional work\n",
    "- Choose a CV or NLP problem. Do a thorough Exploratory Data Analysis of the dataset and report the final performance metrics for your approach.Suggest ways in which you can improve the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a30718-1b11-4a7f-b34a-d5a183220fb3",
   "metadata": {},
   "source": [
    "## Frame the Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61fd9e5f-aef1-4f7b-96b2-57008949f432",
   "metadata": {},
   "source": [
    "- This is an IMDB dataset having 50K movie reviews for natural language processing.\r",
    "- It is a  binary sentiment classificatios.It consists ofaa  set of 25,000positive and 25,000 negative reviews.."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db4ee05d-637b-473a-9710-bc64decfa9e9",
   "metadata": {},
   "source": [
    "## Objective"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35999fa7-e29f-45a1-a402-ca871ad603cc",
   "metadata": {},
   "source": [
    "- The objective is to predict the number of positive and negative reviews using either classification or deep learning algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd171ef9-6bd0-4c3a-a9f9-a7745783d469",
   "metadata": {},
   "source": [
    "## Top Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "449b6bf7-8139-4f8c-ba4a-eeb5e071a456",
   "metadata": {},
   "source": [
    "The highest level of accuracy achieved with this dataset is 96.21 Accuracy in the [XLNet: Generalized Autoregressive Pretraining for Language Understanding](https://paperswithcode.com/sota/sentiment-analysis-on-imdb) paper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cae7b54-9637-4b01-bc4e-04cb93b0697e",
   "metadata": {},
   "source": [
    "## Performance Measure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "920c011b-5dc4-44cc-beba-9c6159f3704a",
   "metadata": {},
   "source": [
    "## Data Source\n",
    "https://www.kaggle.com/datasets/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews/data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e94f052-17fd-4593-b27c-8e3c51cd0d27",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "045b9d74-5a44-42c2-a73d-27c6e3d0302d",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '../Data/Raw/IMDB Dataset.csv'\n",
    "PREPROCESSED_PATH = \"../Data/Processed/preprocessed_df.pkl\"\n",
    "\n",
    "MLFLOW_TRACKING_URI = '../Models/mlruns'\n",
    "MLFLOW_EXPERIMENT_NAME = \"imdb_review_sentiment_analysis\"\n",
    "LOG_PATH = \"../Models/temp/\"\n",
    "LOG_DATA_PKL    =  \"data.pkl\"\n",
    "LOG_MODEL_PKL   =  \"model.pkl\"\n",
    "LOG_METRICS_PKL =  \"metrics.pkl\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b62351-0b5c-47d1-9ad8-e695f74e3ff1",
   "metadata": {},
   "source": [
    "## Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3cd1da-14fa-47fa-a1a8-9bcbf477ae86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import logging\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "import re\n",
    "import string\n",
    "import spacy\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "\n",
    "# pd.options.display.max_rows = 10000\n",
    "# pd.options.display.max_columns = 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74adf740-d82c-4ae1-bfee-43d3a536c24f",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69933548-90cb-4102-94c7-62fc33dd72eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to log Data, Model, Metrics and Track models.\n",
    "def log_data(x_train,y_train,x_test,y_test):\n",
    "    # Save the model's dataset trained on\n",
    "    data_details = {\n",
    "                    \"x_train\": x_train,\n",
    "                    \"x_test\": x_test,\n",
    "                    \"y_train\": y_train,\n",
    "                    \"y_test\": y_test\n",
    "    }\n",
    "\n",
    "    with open(os.path.join(LOG_PATH, LOG_DATA_PKL), \"wb\") as output_file:\n",
    "        pickle.dump(data_details, output_file)\n",
    "        \n",
    "        \n",
    "def log_model(clf,model_description=''):\n",
    "    # save the model, model details and model's description\n",
    "    model = {\"model_description\": model_description,\n",
    "             \"model_details\": str(clf),\n",
    "             \"model_object\": clf} \n",
    "\n",
    "    with open(os.path.join(LOG_PATH, LOG_MODEL_PKL), \"wb\") as output_file:\n",
    "        pickle.dump(model, output_file)\n",
    "        \n",
    "    return model\n",
    "        \n",
    "def log_metrics(train_scores, test_scores):\n",
    "    # save the model metrics\n",
    "    classes_metrics = {\"train_scores\": train_scores,\n",
    "                        \"test_scores\" : test_scores} \n",
    "\n",
    "\n",
    "    with open(os.path.join(LOG_PATH, LOG_METRICS_PKL), \"wb\") as output_file:\n",
    "        pickle.dump(classes_metrics, output_file)\n",
    "\n",
    "def track_model(model, scores):\n",
    "    # Start a run in the experiment and track current model\n",
    "    with mlflow.start_run(experiment_id=exp.experiment_id, run_name=model[\"model_description\"]):\n",
    "        # Track pickle files\n",
    "        mlflow.log_artifacts(LOG_PATH)\n",
    "\n",
    "        # Track metrics \n",
    "        for metric, score in scores.items():\n",
    "            mlflow.log_metric(metric, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad130dd-2523-49af-9608-2d7c17fcb0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count number of characters \n",
    "def chars_count(text):\n",
    "    return len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23c9f0a-a889-425c-abb9-0820eff50006",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count number of words \n",
    "def words_count(text):\n",
    "    return len(text.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb02b447-0d44-4d6d-b41a-9c750cb17c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count number of capital words\n",
    "def capital_words_count(text):\n",
    "    return sum(map(str.isupper,text.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f069661f-dc75-47d5-b5aa-5a4d42b30e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count number of punctuations\n",
    "def punctuations_count(text):\n",
    "    punctuations='!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'\n",
    "    d=dict()\n",
    "    for i in punctuations:\n",
    "        d[str(i)+' count']=text.count(i)\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8871682f-455e-4251-abb1-353af1f1ade9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count number of words in quotes\n",
    "def words_in_quotes_count(text):\n",
    "    x = re.findall(\"\\'.\\'|\\\".\\\"\", text)\n",
    "    count=0\n",
    "    if x is None:\n",
    "        return 0\n",
    "    else:\n",
    "        for i in x:\n",
    "            t=i[1:-1]\n",
    "            count+=count_words(t)\n",
    "        return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b676c53-3d14-45ad-bd65-f961378a36e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count number of sentences\n",
    "def sent_count(text):\n",
    "    return len(nltk.sent_tokenize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95a1fbc-af1a-4c77-bfa8-3f5901957e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate average word length\n",
    "def avg_word_len(char_count,word_count):\n",
    "    return char_count/word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd823f6-42f5-4434-a544-de3c7a814585",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate average sentence length\n",
    "def avg_sent_len(word_count,sent_count):\n",
    "    return word_count/sent_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d1a841-6c83-45a0-acd9-cd2f01a928ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count number of unique words \n",
    "def unique_words_count(text):\n",
    "    return len(set(text.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f3bc43-1cc6-4bd2-b983-fd1274682ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the percentage of unique words\n",
    "def unique_words_percent(unique_count,words_count):\n",
    "    return unique_count/words_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275fd0a3-c0b0-4fa0-a88e-7b116eda2441",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count of stopwords\n",
    "def stopwords_count(text):\n",
    "    stop_words = set(stopwords.words('english'))  \n",
    "    word_tokens = word_tokenize(text)\n",
    "    stopwords_x = [w for w in word_tokens if w in stop_words]\n",
    "    return len(stopwords_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd742a5-2e6e-4114-ab8d-b42cd7288263",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stopwords vs words\n",
    "def stopwords_percent(stopwords_count,text):\n",
    "    return stopwords_count/len(word_tokenize(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f5ce12-46d2-47bd-852a-abdb3d950a48",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "450aa7a8-3dc9-484d-aa80-128966304a36",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 2)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read Dataset and print shape\n",
    "raw_df = pd.read_csv(DATA_PATH)\n",
    "raw_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b35128-22bf-4044-9249-a8b996b397ac",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "001b91b9-b498-4371-a22a-4a17a033caaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50000 entries, 0 to 49999\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   review     50000 non-null  object\n",
      " 1   sentiment  50000 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 781.4+ KB\n"
     ]
    }
   ],
   "source": [
    "raw_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e32fcbe5-fe27-4202-9e5c-e1eab948b20c",
   "metadata": {},
   "source": [
    "- The Dataset contains only two columns\n",
    "- Review column is the training data and Sentiment is the labels column\n",
    "- The dataset doesn't have null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "249de89e-2279-4d47-bda4-0f92edd1c3b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    49582\n",
       "True       418\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for Duplicates\n",
    "raw_df.duplicated().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ab55bc-c24c-4ccd-b239-4e023941c9ca",
   "metadata": {},
   "source": [
    "- The Dataset Contains 418 Duplicated samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cd7ddf52-aeb4-4cb7-9a4f-f2ca5f9e1f09",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Remove the Duplicates\n",
    "raw_df = raw_df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9a3a6a27-957d-4652-87d3-04c8ed6b17fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "positive    24884\n",
       "negative    24698\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check whether the dataset is balanced or imbalanced?\n",
    "raw_df['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a9bf8e-310b-45a2-8aca-b2eb9c46e570",
   "metadata": {},
   "source": [
    "- The Dataset is Balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2c9beff7-5f90-4efc-9dd9-05aa2e4d3bdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# Check whether any empty reviews exist\n",
    "raw_df['length'] = raw_df['review'].apply(len)\n",
    "print(len(raw_df[raw_df['length'] == 0]))\n",
    "raw_df = raw_df.drop(columns='length')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f934a75-3176-4476-a2e8-830bbcfda83a",
   "metadata": {},
   "source": [
    "- The Dataset doesn't have empty reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "007a1bf1-8c2f-4caf-9c5c-b92dc67d1f4e",
   "metadata": {},
   "source": [
    "### Text preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "19ba6bd5-4140-4ca4-a742-844507f65e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = raw_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8a18533d-2055-42b4-bbc7-0224c9544b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert text to lowercase\n",
    "raw_df['review_cleaned'] = raw_df['review'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "732c713c-6a3c-4bc7-bd21-8a0a553e92eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove HTML tags\n",
    "raw_df['review_cleaned'] = raw_df['review_cleaned'].apply(lambda x: re.sub('<[^<]+?>', ' ', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a8bcd9c3-e406-4d8b-b58e-2dc61055842a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Punctuations\n",
    "# raw_df['review'] = raw_df['review'].str.translate(str.maketrans('', '', string.punctuation))\n",
    "raw_df['review_cleaned'] = raw_df['review_cleaned'].apply(lambda x: re.sub(f\"[{re.escape(string.punctuation)}]\",' ', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1cb6fb44-8c48-4851-87fa-fcc7038d7f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Digits\n",
    "raw_df['review_cleaned'] = raw_df['review_cleaned'].apply(lambda x: re.sub(r'\\d+', '', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f983b815-48e0-4d79-9f19-6ae23eeaf629",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove URLs\n",
    "raw_df['review_cleaned'] = raw_df['review_cleaned'].apply(lambda x: re.sub(r'https?://\\S+|www\\.\\S+', '', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2f289335-d6fa-4daf-af45-32cdcb0940aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new column with No StopWords\n",
    "stop_words = stopwords.words('english')\n",
    "raw_df['review_nostopwords'] = raw_df['review_cleaned'].apply(lambda x: ' '.join([word for word in x.split() if word not in stop_words]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5c174b4d-6bca-4180-9f7d-96605ff702fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new column for stemmed words\n",
    "stemmer = PorterStemmer()\n",
    "raw_df[\"review_stemmed\"] = raw_df[\"review_nostopwords\"].apply(lambda x: \" \".join([stemmer.stem(word) for word in x.split()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424cdf9e-d575-4670-9130-8c02f7bf4f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new column for lemmatized words \n",
    "#Load English tokenizer, tagger, parser and NER\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "# Process the text using spaCy and Extract lemmatized tokens\n",
    "raw_df['review_lemma'] = raw_df[\"review_nostopwords\"].apply(lambda x: \" \".join([word.lemma_ for word in nlp(x)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fab5790-b8c1-4be1-8d0c-b1f9dc18dd18",
   "metadata": {},
   "source": [
    "- Applying Text preprocessing in that specific order resulted in the most clean Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43bd568f-412f-496f-a44b-ee82bd497883",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Verify your Results\n",
    "i = df.sample(1).index[0]\n",
    "# i = 100\n",
    "print(raw_df['review_lemma'].iloc[i])\n",
    "print('###########################################################')\n",
    "print(df['review'].iloc[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98039bf-e1ea-41f8-9df1-68040a57a21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the preprocessed dataset with pickle\n",
    "raw_df.to_pickle(PREPROCESSED_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a18e6f-d8ef-4202-9870-748b8514b350",
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_df = pd.read_pickle(PREPROCESSED_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce2a841-1f12-4f9f-b448-57e9af95e0f7",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984e1d25-1cb7-4c43-ba3e-9a460557ea85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ffc247b2-a2f0-4527-a702-fbbfcd6b8fa4",
   "metadata": {},
   "source": [
    "### Text Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f39e09a9-adff-437e-93e1-9b9c5f2777f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intilize \n",
    "tf_idf = TfidfVectorizer(ngram_range=(1,2))\n",
    "\n",
    "# Fitting\n",
    "tf = tf_idf.fit_transform(raw_df['review_lemma'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72164569-7e38-4c23-b773-c7fb8ac51aae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Lenght of Tf-idf Vocabulary is 2750963\n"
     ]
    }
   ],
   "source": [
    "# Len of Vocabulary\n",
    "print(f\"The Lenght of Tf-idf Vocabulary is {len(tf_idf.vocabulary_)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e204da73-c33a-458c-91b4-49350ffff334",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf\n",
    "y = raw_df['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "73ef20d9-4f10-4f59-b9b7-055322fde81f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IDF Scores of Words: [ 9.17234598 11.11825613 11.11825613 ... 11.11825613 11.11825613\n",
      " 11.11825613]\n"
     ]
    }
   ],
   "source": [
    "# IDF scores of words\n",
    "idf_scores = tf_idf.idf_\n",
    "\n",
    "# Print the IDF scores of words and the vocabulary\n",
    "print(\"IDF Scores of Words:\", idf_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "84aedb0c-d2c7-48df-856a-bfca76619b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BAG of words\n",
    "cv = CountVectorizer(ngram_range=(1,2))\n",
    "traindata = cv.fit_transform(raw_df['review'])\n",
    "x = traindata\n",
    "y = raw_df['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c570fc43-e76a-4ba1-932d-3701df5afc26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49582, 2451230)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d79082a-93d9-4b64-bd27-723def2860e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dfc04935-8d00-463e-85ec-7e30e125d586",
   "metadata": {},
   "source": [
    "### Intialize MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b374343b-2242-418b-8506-5b5518cc5e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Directories\n",
    "Path(MLFLOW_TRACKING_URI).mkdir(parents=True, exist_ok=True)\n",
    "Path(LOG_PATH).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d373b86-165b-4eaf-b5a7-9f9d87ae1c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize client and experiment\n",
    "mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)\n",
    "client = MlflowClient()\n",
    "mlflow.set_experiment(MLFLOW_EXPERIMENT_NAME)\n",
    "exp = client.get_experiment_by_name(MLFLOW_EXPERIMENT_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dbc29a9-34a4-4045-b60e-9be26fd3e490",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0e3145c9-c565-42c6-baa3-c8253773963d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = raw_df.iloc[0:,0].values\n",
    "y = raw_df.iloc[0:,1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0ba6b560-5d83-4f7f-a5f0-ae28139b1b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size = 0.25,random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "64072f03-70b3-4edf-bc6a-a60e1e16065d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = TfidfVectorizer()\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a1f226af-5918-4557-8e76-8c77dbef681d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;vectorizer&#x27;, TfidfVectorizer()),\n",
       "                (&#x27;Log_clf&#x27;, LogisticRegression())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;vectorizer&#x27;, TfidfVectorizer()),\n",
       "                (&#x27;Log_clf&#x27;, LogisticRegression())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('vectorizer', TfidfVectorizer()),\n",
       "                ('Log_clf', LogisticRegression())])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "log_clf =LogisticRegression()\n",
    "model=Pipeline([('vectorizer',tf),('Log_clf',log_clf)])\n",
    "\n",
    "model.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b775a939-82be-4743-8a80-c785219984f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=10000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=10000)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=10000)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "log_clf = LogisticRegression(max_iter=10000)\n",
    "log_clf.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "11a30f89-a8a4-46df-98f6-1de7073b12a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=log_clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4e7e04bc-9932-43b3-affd-8f77d0866b60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8950467892868668\n"
     ]
    }
   ],
   "source": [
    "# model score\n",
    "accuracy=accuracy_score(y_pred,y_test)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cff3b3c5-a7f3-4226-a361-ef4691fb7894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5450  718]\n",
      " [ 583 5645]]\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix\n",
    "cm=confusion_matrix(y_test,y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f830e315-e78f-4017-80c2-faa2e63fbcb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: 0.9033648267860103, Recall: 0.8835927367055771, F1: 0.8933693959511515\n"
     ]
    }
   ],
   "source": [
    "recall= recall_score(y_test, y_pred, average=\"binary\", pos_label=\"negative\")\n",
    "precision = precision_score(y_test, y_pred, average=\"binary\", pos_label=\"negative\")\n",
    "f1 = f1_score(y_test, y_pred, average=\"binary\", pos_label=\"negative\")\n",
    "print(f\"precision: {precision}, Recall: {recall}, F1: {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cc059838-290c-46c5-821c-a39bb8a15b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores={'accuracy' : accuracy,\n",
    "        'precision' : precision,\n",
    "        'recall' : recall,\n",
    "        'f1': f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "901c7ab3-e01a-49f1-91ed-710c75603304",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.8950467892868668,\n",
       " 'precision': 0.9033648267860103,\n",
       " 'recall': 0.8835927367055771,\n",
       " 'f1': 0.8933693959511515}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6c93b033-833c-4844-a1f5-ffa0185d8ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log the model's dataset train and test indices\n",
    "log_data(x_train,y_train,x_test,y_test)\n",
    "# Log the model, model description\n",
    "model = log_model(log_clf,'Log ReG, BOW, 1,2 bigram')\n",
    "# Log the model's train and test scores\n",
    "log_metrics(scores, scores)\n",
    "# track the model artifacts, validation scores with mlflow\n",
    "track_model(model,scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eaec30a-34ed-4fc5-a4d5-ad109bb1bfc3",
   "metadata": {},
   "source": [
    "## Retrieve Runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b744475b-165e-4765-b7a3-6ad006623470",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_id</th>\n",
       "      <th>tags.mlflow.runName</th>\n",
       "      <th>metrics.precision</th>\n",
       "      <th>metrics.recall</th>\n",
       "      <th>metrics.f1</th>\n",
       "      <th>metrics.accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ffdb5813bf0a47318f9c67012a3cf6a6</td>\n",
       "      <td>Log ReG, BOW, 1,2 bigram</td>\n",
       "      <td>0.903365</td>\n",
       "      <td>0.883593</td>\n",
       "      <td>0.893369</td>\n",
       "      <td>0.895047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6b4b59c8d3fb429c934e7968d7bf7901</td>\n",
       "      <td>Log ReG, BOW, 1,2 bigram,lemma</td>\n",
       "      <td>0.903365</td>\n",
       "      <td>0.883593</td>\n",
       "      <td>0.893369</td>\n",
       "      <td>0.895047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dacb0747953943b6ac752d36f2bcf578</td>\n",
       "      <td>Log ReG, tf-idf, 1,2 bigram,lemma</td>\n",
       "      <td>0.902224</td>\n",
       "      <td>0.861706</td>\n",
       "      <td>0.881499</td>\n",
       "      <td>0.884721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7b592fe69d134112a6c84fbdb5c8be4d</td>\n",
       "      <td>Log ReG, tf-idf, 1,2 bigram,no stopwords</td>\n",
       "      <td>0.905906</td>\n",
       "      <td>0.880350</td>\n",
       "      <td>0.892945</td>\n",
       "      <td>0.894966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5ab3454d99494e939b27394a47c9fbe8</td>\n",
       "      <td>Logistic Regression, tf-idf, 1,2 bigram, with ...</td>\n",
       "      <td>0.904408</td>\n",
       "      <td>0.868191</td>\n",
       "      <td>0.885929</td>\n",
       "      <td>0.888754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>d2feaee50f68455781aec918adc780f2</td>\n",
       "      <td>Logistic Regression, BOW, 1,2 bigram, with sto...</td>\n",
       "      <td>0.913295</td>\n",
       "      <td>0.896563</td>\n",
       "      <td>0.904852</td>\n",
       "      <td>0.906179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>a8c1d3ee67f64b37bf587ea7dd4a2a30</td>\n",
       "      <td>Logistic Regression, BOW, bigram</td>\n",
       "      <td>0.879706</td>\n",
       "      <td>0.833495</td>\n",
       "      <td>0.855977</td>\n",
       "      <td>0.860439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>36ca8b6129ad46e48c10794db3844bb0</td>\n",
       "      <td>Logistic Regression, BOW, unigram</td>\n",
       "      <td>0.889072</td>\n",
       "      <td>0.874514</td>\n",
       "      <td>0.881733</td>\n",
       "      <td>0.883269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>50741e3566b344c0a60535724167a91e</td>\n",
       "      <td>Logistic Regression, BOW,</td>\n",
       "      <td>0.903157</td>\n",
       "      <td>0.886025</td>\n",
       "      <td>0.894509</td>\n",
       "      <td>0.896015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1f4e81e7082c414dbf4acaafad7b6e4e</td>\n",
       "      <td>Logistic Regression, Tf-idf, lemma</td>\n",
       "      <td>0.900868</td>\n",
       "      <td>0.875162</td>\n",
       "      <td>0.887829</td>\n",
       "      <td>0.889965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>9a0008c93ee94e86b9ca9ec32c59d0f5</td>\n",
       "      <td>Baseline model: Logistic Regression, Tf-idf, s...</td>\n",
       "      <td>0.902214</td>\n",
       "      <td>0.872082</td>\n",
       "      <td>0.886892</td>\n",
       "      <td>0.889319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ac24c3282c524669bd23bc21092e0ac6</td>\n",
       "      <td>Baseline model: Logistic Regression, Tf-idf</td>\n",
       "      <td>0.904849</td>\n",
       "      <td>0.877270</td>\n",
       "      <td>0.890846</td>\n",
       "      <td>0.893030</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              run_id  \\\n",
       "0   ffdb5813bf0a47318f9c67012a3cf6a6   \n",
       "1   6b4b59c8d3fb429c934e7968d7bf7901   \n",
       "2   dacb0747953943b6ac752d36f2bcf578   \n",
       "3   7b592fe69d134112a6c84fbdb5c8be4d   \n",
       "4   5ab3454d99494e939b27394a47c9fbe8   \n",
       "5   d2feaee50f68455781aec918adc780f2   \n",
       "6   a8c1d3ee67f64b37bf587ea7dd4a2a30   \n",
       "7   36ca8b6129ad46e48c10794db3844bb0   \n",
       "8   50741e3566b344c0a60535724167a91e   \n",
       "9   1f4e81e7082c414dbf4acaafad7b6e4e   \n",
       "10  9a0008c93ee94e86b9ca9ec32c59d0f5   \n",
       "11  ac24c3282c524669bd23bc21092e0ac6   \n",
       "\n",
       "                                  tags.mlflow.runName  metrics.precision  \\\n",
       "0                            Log ReG, BOW, 1,2 bigram           0.903365   \n",
       "1                     Log ReG, BOW, 1,2 bigram,lemma            0.903365   \n",
       "2                  Log ReG, tf-idf, 1,2 bigram,lemma            0.902224   \n",
       "3           Log ReG, tf-idf, 1,2 bigram,no stopwords            0.905906   \n",
       "4   Logistic Regression, tf-idf, 1,2 bigram, with ...           0.904408   \n",
       "5   Logistic Regression, BOW, 1,2 bigram, with sto...           0.913295   \n",
       "6                   Logistic Regression, BOW, bigram            0.879706   \n",
       "7                  Logistic Regression, BOW, unigram            0.889072   \n",
       "8                          Logistic Regression, BOW,            0.903157   \n",
       "9                  Logistic Regression, Tf-idf, lemma           0.900868   \n",
       "10  Baseline model: Logistic Regression, Tf-idf, s...           0.902214   \n",
       "11        Baseline model: Logistic Regression, Tf-idf           0.904849   \n",
       "\n",
       "    metrics.recall  metrics.f1  metrics.accuracy  \n",
       "0         0.883593    0.893369          0.895047  \n",
       "1         0.883593    0.893369          0.895047  \n",
       "2         0.861706    0.881499          0.884721  \n",
       "3         0.880350    0.892945          0.894966  \n",
       "4         0.868191    0.885929          0.888754  \n",
       "5         0.896563    0.904852          0.906179  \n",
       "6         0.833495    0.855977          0.860439  \n",
       "7         0.874514    0.881733          0.883269  \n",
       "8         0.886025    0.894509          0.896015  \n",
       "9         0.875162    0.887829          0.889965  \n",
       "10        0.872082    0.886892          0.889319  \n",
       "11        0.877270    0.890846          0.893030  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runs = mlflow.search_runs([exp.experiment_id])\n",
    "runs[['run_id','tags.mlflow.runName','metrics.precision','metrics.recall','metrics.f1','metrics.accuracy']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "69e9bc02-fca3-4884-be21-700d5a6a0b4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Logistic Regression, BOW, 1,2 bigram, with stopwords '"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runs['tags.mlflow.runName'].iloc[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64aa5cff-7f7d-49c9-97af-d30d57322adf",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis\n",
    "#### Questions wee need to answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c401d400-aed2-46a1-bdb1-01a0ace76be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b104fe8-1bc8-485b-b791-345da20fc947",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08151b9c-0fe8-4dfd-8ea3-f7f38746b4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0536e5-90ad-4ae5-b3af-ee7976d884c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df.loc[raw_df['length'] == 32].iloc[0,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa237d78-fa9c-4a15-b5ee-cafef70940b8",
   "metadata": {},
   "source": [
    "### Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dbc8f9f-817e-4274-a47b-b179b836a8a4",
   "metadata": {},
   "source": [
    "We can observed that both logistic regression and multinomial naive bayes model performing well compared to linear support vector machines.\r\n",
    "Still we can improve the accuracy of the models by preprocessing data and by using lexicon models like Textblob."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb6e67a-323c-4367-b00d-e8cd013ca718",
   "metadata": {},
   "source": [
    "Word clouds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91844410-6cbb-4e9a-8a92-3ea5c4d3d33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#word cloud for positive review words\n",
    "plt.figure(figsize=(10,10))\n",
    "positive_text=norm_train_reviews[1]\n",
    "WC=WordCloud(width=1000,height=500,max_words=500,min_font_size=5)\n",
    "positive_words=WC.generate(positive_text)\n",
    "plt.imshow(positive_words,interpolation='bilinear')\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceefae9c-e93c-4857-b5ee-02c71a8b4a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8041174-d796-4cbf-8cc1-a0e863f48754",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
