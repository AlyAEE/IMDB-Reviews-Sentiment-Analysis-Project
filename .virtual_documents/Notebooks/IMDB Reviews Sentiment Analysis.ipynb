





























DATA_PATH = '../Data/Raw/IMDB Dataset.csv'
PREPROCESSED_PATH = "../Data/Processed/preprocessed_df.pkl"
ENGINEERED_PATH = "../Data/Processed/engineered_df.pkl"

MLFLOW_TRACKING_URI = '../Models/mlruns'
MLFLOW_EXPERIMENT_NAME = "imdb_review_sentiment_analysis"
LOG_PATH = "../Models/temp/"
LOG_DATA_PKL    =  "data.pkl"
LOG_MODEL_PKL   =  "model.pkl"
LOG_METRICS_PKL =  "metrics.pkl"





import os
import numpy as np
import pandas as pd

import logging
import pickle
from pathlib import Path

import re
import nltk
import string
import spacy
import scipy.stats as stats
from nltk.tag import pos_tag
from nltk.util import ngrams
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize, sent_tokenize
from nltk.stem import PorterStemmer
from nltk.stem import WordNetLemmatizer
from wordcloud import WordCloud
from collections import Counter
from textblob import TextBlob

import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.decomposition import TruncatedSVD
from sklearn.impute import SimpleImputer
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, precision_score, recall_score, f1_score
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.preprocessing import StandardScaler,RobustScaler
from sklearn.pipeline import make_pipeline
from sklearn.compose import ColumnTransformer
from sklearn.linear_model import LogisticRegression


import mlflow
from mlflow.tracking import MlflowClient


# pd.options.display.max_rows = 10000
# pd.options.display.max_columns = 10000





# Create a Folder named Images to save figures in.
IMAGES_PATH = Path.cwd().parent / "Images"
IMAGES_PATH.mkdir(parents=True, exist_ok=True)

def save_fig(fig_id, tight_layout=True, fig_extension="png", resolution=300):
    """
    This functions will save the current figure shown below.
    
    Args:
        fig_id: String Containing the name of the figure.
        tight_layout: Boolean to decide whether you want a tight layout or not.
        fig_extension: String to decide the type of the figure.
        resoultion: Int to decide the resolution of the figure.
        
    Returns:
        None
    """
    path = IMAGES_PATH / f"{fig_id}.{fig_extension}"
    
    if tight_layout:
        plt.tight_layout()
        
    plt.savefig(path, format=fig_extension, dpi=resolution)


# Function to log Data, Model, Metrics and Track models.
def log_data(x_train,y_train,x_test,y_test):
    # Save the model's dataset trained on
    data_details = {
                    "x_train": x_train,
                    "x_test": x_test,
                    "y_train": y_train,
                    "y_test": y_test
    }

    with open(os.path.join(LOG_PATH, LOG_DATA_PKL), "wb") as output_file:
        pickle.dump(data_details, output_file)
        
        
def log_model(clf,model_description=''):
    # save the model, model details and model's description
    model = {"model_description": model_description,
             "model_details": str(clf),
             "model_object": clf} 

    with open(os.path.join(LOG_PATH, LOG_MODEL_PKL), "wb") as output_file:
        pickle.dump(model, output_file)
        
    return model
        
def log_metrics(train_scores, test_scores):
    # save the model metrics
    classes_metrics = {"train_scores": train_scores,
                        "test_scores" : test_scores} 


    with open(os.path.join(LOG_PATH, LOG_METRICS_PKL), "wb") as output_file:
        pickle.dump(classes_metrics, output_file)

def track_model(model, scores):
    # Start a run in the experiment and track current model
    with mlflow.start_run(experiment_id=exp.experiment_id, run_name=model["model_description"]):
        # Track pickle files
        mlflow.log_artifacts(LOG_PATH)

        # Track metrics 
        for metric, score in scores.items():
            mlflow.log_metric(metric, score)


# count number of characters 
def chars_count(text):
    return len(text)


# count number of words 
def words_count(text):
    return len(text.split())


# count number of capital words
def capital_words_count(text):
    return sum(map(str.isupper,text.split()))


# count number of punctuations
def punctuations_count(text):
    punctuations='!"#$%&\'()*+,-./:;<=>?@[\\]^_`{|}~'
    d=dict()
    for i in punctuations:
        d[str(i)+' count']=text.count(i)
    return d


# count number of words in quotes
def words_in_quotes_count(text):
    x = re.findall("\'.\'|\".\"", text)
    count=0
    if x is None:
        return 0
    else:
        for i in x:
            t=i[1:-1]
            count+=count_words(t)
        return count


# count number of sentences
def sent_count(text):
    return len(sent_tokenize(text))


# count number of unique words 
def unique_words_count(text):
    return len(set(text.split()))


# count of stopwords
def stopwords_count(text):
    stop_words = set(stopwords.words('english'))  
    word_tokens = word_tokenize(text)
    stopwords_x = [w for w in word_tokens if w in stop_words]
    return len(stopwords_x)


# visualize Box plot and KDE plot
def visualize_features(col, legend):

    plt.rcParams["figure.figsize"] = [12, 4]
    plt.rcParams["figure.autolayout"] = True
    f, axes = plt.subplots(1, 2)
    sns.boxplot(x=col, hue=legend, ax=axes[0])
    sns.kdeplot(x=col, hue=legend, ax=axes[1])
    plt.legend(legend.unique())
    axes[0].set_xlabel(f'{col.name[1]} Box Plot')
    axes[1].set_xlabel(f'{col.name[1]} KDE Plot')
    plt.ylabel('')
    plt.suptitle(col.name[1])
    # Save the figure
    save_fig(f'2-{col.name[1]} Box plot and KDE plot')
    plt.show()


# Create n_grams
def create_ngrams(text, n=2):
    text = str(text)
    n_grams = ngrams(text.split(), n)
    returnVal = []
    try:
        for grams in n_grams:
            returnVal.append('_'.join(grams))
    except(RuntimeError):
        pass
    return ' '.join(returnVal).strip()


# Create a wordcloud
def create_wordcloud(data):
    wordcloud = WordCloud(
        background_color='white',
        max_words=200,
        max_font_size=30,
        scale=3,
        random_state=42)

    wordcloud=wordcloud.generate(str(data))

    fig = plt.figure(1, figsize=(12, 12))
    plt.axis('off')

    plt.imshow(wordcloud)
    plt.show()


# pLot bar plot of top n words in a col 
def plot_most_common_words(col,n):

    # Get the vocab in each row
    vocab = col.str.split().values.tolist()
    # Create the corpus of the whole column
    corpus=[word for line in vocab for word in line]

    # Get the most common n words
    counter=Counter(corpus).most_common(n)
    word = []
    count = [] 
    for i, j in counter:
        word.append(i)
        count.append(j)

    # define Seaborn color palette 
    palette_color = sns.color_palette("rocket", n)
    # Set the fig size
    plt.figure(figsize=(10, 10))
    sns.barplot(x= count, y= word)
    plt.title(f'{n} most common words in {col.name} column')
    # Save the figure
    save_fig(f'3-{n} most common words in {col.name} column')
    plt.show()


# GEt pos_tags from the dataset
def pos_tags(df, col, sample):
    # sample data
    df = df.head(sample)
    # create tokens
    tokens = word_tokenize(" ".join(df[col].values.tolist()))
    # create tags
    tags = pos_tag(tokens, tagset = "universal",lang='eng')
    return tags


def get_most_common_pos(tags, pos, tag_count):
    # Get all tokens that are tagged as tags
    tags_list = [word for word, tag in tags if tag == pos]
    # Count most common adjectives
    most_common = Counter(tags_list).most_common(tag_count)
    # word and frequency
    words, frequency = [], []
    for word, count in most_common:
        words.append(word)
        frequency.append(count)
    return words, frequency


def measure_polarity(text):
    
    def _polarity(text):
        return TextBlob(text).sentiment.polarity
        
    polarity_score =text.apply(lambda x : _polarity(x))
    return polarity_score





# Read Dataset and print shape
raw_df = pd.read_csv(DATA_PATH)
raw_df.shape





raw_df.info()





# Check for Duplicates
raw_df.duplicated().value_counts()





# Remove the Duplicates
raw_df = raw_df.drop_duplicates()


# Check whether the dataset is balanced or imbalanced?
raw_df['sentiment'].value_counts()





# Check whether any empty reviews exist
raw_df['length'] = raw_df['review'].apply(len)
print(len(raw_df[raw_df['length'] == 0]))
raw_df = raw_df.drop(columns='length')








df = raw_df.copy()


# Convert text to lowercase
raw_df['review_cleaned'] = raw_df['review'].str.lower()


# Remove HTML tags
raw_df['review_cleaned'] = raw_df['review_cleaned'].apply(lambda x: re.sub('<[^<]+?>', ' ', x))


# Remove Punctuations
# raw_df['review'] = raw_df['review'].str.translate(str.maketrans('', '', string.punctuation))
raw_df['review_cleaned'] = raw_df['review_cleaned'].apply(lambda x: re.sub(f"[{re.escape(string.punctuation)}]",' ', x))


# Remove Digits
raw_df['review_cleaned'] = raw_df['review_cleaned'].apply(lambda x: re.sub(r'\d+', '', x))


# Remove URLs
raw_df['review_cleaned'] = raw_df['review_cleaned'].apply(lambda x: re.sub(r'https?://\S+|www\.\S+', '', x))


# Create new column with No StopWords
stop_words = stopwords.words('english')
raw_df['review_nostopwords'] = raw_df['review_cleaned'].apply(lambda x: ' '.join([word for word in x.split() if word not in stop_words]))


# Create new column for stemmed words
stemmer = PorterStemmer()
raw_df["review_stemmed"] = raw_df["review_nostopwords"].apply(lambda x: " ".join([stemmer.stem(word) for word in x.split()]))


# Create new column for lemmatized words 
#Load English tokenizer, tagger, parser and NER
nlp = spacy.load("en_core_web_sm")
# Process the text using spaCy and Extract lemmatized tokens
raw_df['review_lemma'] = raw_df["review_nostopwords"].apply(lambda x: " ".join([word.lemma_ for word in nlp(x)]))





# Verify your Results
i = df.sample(1).index[0]
# i = 100
print(raw_df['review_stemmed'].iloc[i])
print('###########################################################')
print(df['review'].iloc[i])


# Export the preprocessed dataset with pickle
raw_df.to_pickle(PREPROCESSED_PATH)


prep_df = pd.read_pickle(PREPROCESSED_PATH).reset_index(drop=True)





featured_df = prep_df.copy()


# Add a char count feature
featured_df['char_count'] = prep_df['review_cleaned'].apply(lambda x: chars_count(x))


# Add a word count feature
featured_df['word_count'] = prep_df['review_cleaned'].apply(lambda x: words_count(x))


# Add a sentence count feature
featured_df['sent_count'] = prep_df['review'].apply(lambda x: sent_count(x))


# Add a feature for the count of capital characters 
featured_df['capital_char_count'] = prep_df['review'].apply(lambda x: capital_words_count(x)) 


# Add a feature for the count of words in quotes
featured_df['words_in_quotes_count'] = prep_df['review'].apply(lambda x: words_in_quotes_count(x))


# Add a feature for the count of stopwords
featured_df['stopwords_count'] = prep_df['review'].apply(lambda x: stopwords_count(x))


# Add a feature for the count of unique words
featured_df['unique_words_count'] = prep_df['review_nostopwords'].apply(lambda x: unique_words_count(x))


# Add a punctuations count feature
featured_df['punctuations_count'] = prep_df['review'].apply(lambda x: punctuations_count(x))


# Add Average word length feature
featured_df['avg_word_len'] = featured_df['char_count'] / featured_df['word_count']


# Add Average sentence length feature
featured_df['avg_sent_len'] = featured_df['word_count'] / featured_df['sent_count']


# Add unique words percentage feature
featured_df['unique_words_percent'] = featured_df['unique_words_count'] / featured_df['word_count']


# Add a stopwords percentage feature
featured_df['stopwords_percent'] = featured_df['stopwords_count'] / featured_df['word_count']


featured_df = featured_df.drop(columns=prep_df.columns)


punct_cols = pd.DataFrame(list(featured_df.punctuations_count))
punct_cols.columns = pd.MultiIndex.from_product([['punct_cols'], punct_cols.columns])


featured_df = featured_df.drop('punctuations_count', axis=1)


featured_df.columns = pd.MultiIndex.from_product([['featured_cols'], featured_df.columns])


featured_df= pd.concat([featured_df,punct_cols],axis=1)


## Add the polarity score feature, This is done after EDA
featured_df['featured_cols','polarity'] = measure_polarity(prep_df['review_nostopwords'])


featured_df = featured_df.drop('polarity', axis = 1,level = 0)


# Export the preprocessed dataset with pickle
featured_df.to_pickle(ENGINEERED_PATH)


featured_df = pd.read_pickle(ENGINEERED_PATH)





temp_df = prep_df.copy()


featured_df.describe()





# Convert the sentiments to integer labels
temp_df['labels'] = temp_df['sentiment'].apply(lambda x: 1 if x == 'positive' else 0)


# Since we are dealing with independent Continuous features and dependent Categorical features
# We will use the point_biserial correlation

#calculate point-biserial correlation
corr = featured_df['featured_cols'].corrwith(temp_df['labels'].astype('float'), method=stats.pointbiserialr)
corr.rename(index={0: 'Correlation', 1: 'P_value'}, inplace=True)
corr = corr.style.format('{:.5f}')
corr





#calculate point-biserial correlation
corr = featured_df['punct_cols'].corrwith(temp_df['labels'].astype('float'), method=stats.pointbiserialr)
corr.rename(index={0: 'Correlation', 1: 'P_value'}, inplace=True)
corr = corr.style.format('{:.5f}')
corr








corr = featured_df['featured_cols'].corr(numeric_only= True)
# plot the heatmap

# Set up the matplotlib figure
f, ax = plt.subplots(figsize=(15, 10))

sns.heatmap(corr, 
            cmap=sns.diverging_palette(240, 10, as_cmap=True),                        
            cbar_kws={"shrink": .5}, annot=True,annot_kws={"fontsize":8}
            )
# Save the figure
save_fig('1-new_features_correlation')
plt.show()








# Plot the Box plot and KDE plot 
cols = featured_df['featured_cols'].columns.tolist()
for col in cols:
    visualize_features(featured_df['featured_cols', col], temp_df['sentiment'])








# Calculate Skewness and Kurtosis.
cols = featured_df['featured_cols'].columns.tolist()
for col in cols:
    print(f"Feature: {col}")
    print(f"Skew: {featured_df['featured_cols', col].skew()}")
    print(f"Kurtosis: {featured_df['featured_cols', col].kurtosis()}")
    print("#################################################")








# Plot the most common 50 unigram words in the dataset
plot_most_common_words(temp_df['review_nostopwords'], 50)





# create n-grams for analysis
temp_df["bigram_text"] = temp_df['review_nostopwords'].apply(create_ngrams, n=2)
temp_df["trigram_text"] = temp_df['review_nostopwords'].apply(create_ngrams, n=3)
temp_df["quadgram_text"] = temp_df['review_nostopwords'].apply(create_ngrams, n=4)


# Plot the most common 50 bigram words in the dataset
plot_most_common_words(temp_df['bigram_text'], 50)





# Plot the most common 50 trigram words in the dataset
plot_most_common_words(temp_df['trigram_text'], 50)


# Plot the most common 50 quadgram words in the dataset
plot_most_common_words(temp_df['quadgram_text'], 50)








tags = pos_tags(temp_df, 'review_nostopwords',5000)


# Get most_common Adjectives
adj_word_pos, adj_freq_pos = get_most_common_pos(tags, 'ADJ', 50)
# plot the bar plot
plt.rcParams["figure.figsize"] = [8, 6]
plt.rcParams["figure.autolayout"] = True
sns.barplot(x = pd.Series(adj_freq_pos), y = pd.Series(adj_word_pos))
plt.title('Top 50 Adjectives')
plt.show()


# Get Most common Nouns
noun_word_pos, noun_freq_pos = get_most_common_pos(tags, 'NOUN', 50)
# plot the bar plot
plt.rcParams["figure.figsize"] = [8, 6]
plt.rcParams["figure.autolayout"] = True
sns.barplot(x = pd.Series(noun_freq_pos), y = pd.Series(noun_word_pos))
plt.title('Top 50 Nouns')
plt.show()


# Get Most common Verbs
verb_word_pos, verb_freq_pos = get_most_common_pos(tags, 'VERB', 50)
# plot the bar plot
plt.rcParams["figure.figsize"] = [8, 6]
plt.rcParams["figure.autolayout"] = True
sns.barplot(x = pd.Series(verb_freq_pos), y = pd.Series(verb_word_pos))
plt.title('Top 50 Verbs')
plt.show()





# measure polarity using text blob sentiment polarity
scores = measure_polarity(temp_df['review_nostopwords'])


scores.hist()





temp_df['polarity_score'] = scores


def sentiment(x):
    if x<0:
        return 'negative'
    elif x==0:
        return 'neutral'
    else:
        return 'positive'

temp_df['polarity']=temp_df['polarity_score'].map(lambda x: sentiment(x))

plt.bar(temp_df.polarity.value_counts().index,
        temp_df.polarity.value_counts())


accuracy=accuracy_score(temp_df['polarity'],temp_df['sentiment'])
print(accuracy)





corr = scores.corr(temp_df['labels'].astype('float'), method=stats.pointbiserialr)


corr








prep_df = pd.read_pickle(PREPROCESSED_PATH).reset_index(drop=True)


featured_df = pd.read_pickle(ENGINEERED_PATH)





# Create Directories
Path(MLFLOW_TRACKING_URI).mkdir(parents=True, exist_ok=True)
Path(LOG_PATH).mkdir(parents=True, exist_ok=True)


# Initialize client and experiment
mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)
client = MlflowClient()
mlflow.set_experiment(MLFLOW_EXPERIMENT_NAME)
exp = client.get_experiment_by_name(MLFLOW_EXPERIMENT_NAME)





# Get a list of the names of coulmns in featured_df
featured_cols = featured_df['featured_cols'].columns.tolist()
punct_cols = featured_df['punct_cols'].columns.tolist()
num_cols = featured_cols +  punct_cols
# Remove the multi_index from featured_df
featured_df = featured_df.droplevel(0,axis = 1).copy()
# Convert the sentiments to integer labels 
prep_df['labels'] = prep_df['sentiment'].apply(lambda x: 1 if x == 'positive' else 0)


# Merge the new features with the lemmatized reviews and labels
model_df = pd.concat([featured_df,prep_df[['review_cleaned','labels']]], axis= 1)


# Split the Dataset, No need to stratify split since the dataset is balanced
x_train, x_test, y_train, y_test = train_test_split(model_df.drop(['labels'],axis=1),model_df['labels'] ,test_size = 0.20,random_state = 42)


y_train.value_counts()


y_test.value_counts()











# create pipeline for numerical attributes
num_pipeline = make_pipeline(SimpleImputer(strategy='median'),
                               RobustScaler())
 
# create pipeline for Text attributes                            
vectorizer_pipeline = make_pipeline(CountVectorizer(ngram_range=(1,2)))

# Combine both num and cate pipeline using column transformer
full_pipeline = ColumnTransformer([
    # ("num", num_pipeline, num_cols),
    ("vectorizer", vectorizer_pipeline, 'review_cleaned')])


# apply all transformations
x_train_pipe = full_pipeline.fit_transform(x_train)
x_train_pipe





log_clf = LogisticRegression(max_iter = 1000)
log_clf.fit(x_train_pipe, y_train)


# apply transformation on the test set
x_test_pipe = full_pipeline.transform(x_test)


y_pred=log_clf.predict(x_test_pipe)


# model score
accuracy=accuracy_score(y_pred,y_test)
print(accuracy)


# confusion matrix
cm=confusion_matrix(y_test,y_pred)
print(cm)


recall= recall_score(y_test, y_pred, average="binary")
precision = precision_score(y_test, y_pred, average="binary")
f1 = f1_score(y_test, y_pred, average="binary")
print(f"precision: {precision}, Recall: {recall}, F1: {f1}")


scores={'accuracy' : accuracy,
        'precision' : precision,
        'recall' : recall,
        'f1': f1}


scores


# Log the model's dataset train and test indices
log_data(x_train,y_train,x_test,y_test)
# Log the model, model description
model = log_model(log_clf,'Base:Log ReG,BOW,1,2ngram, withstopwords')
# Log the model's train and test scores
log_metrics(scores, scores)
# track the model artifacts, validation scores with mlflow
track_model(model,scores)























runs = mlflow.search_runs([exp.experiment_id])
runs[['run_id','tags.mlflow.runName','metrics.precision','metrics.recall','metrics.f1','metrics.accuracy']]



